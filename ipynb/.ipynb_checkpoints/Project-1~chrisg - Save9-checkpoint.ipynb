{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Dependencies\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import random as rd\n",
    "np.random.seed(sum(map(ord, \"aesthetics\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8664\n"
     ]
    }
   ],
   "source": [
    "## Read file and then sort \n",
    "csv_file = \"a_companies.csv\"\n",
    "companies_df = pd.read_csv(csv_file, encoding=\"iso-8859-1\",\n",
    "                           parse_dates=[\"Founded Date\",\"Closed Date\",\n",
    "                                        \"Last Funding Date\"])\n",
    "companies_df = companies_df.sort_values(\"Company Name\").reset_index(drop=True)\n",
    "#companies_df.columns\n",
    "print(len(companies_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "companies_df = companies_df[[\"Company Name\", \"Founded Date\", \"Closed Date\", \n",
    "                             \"Number of Funding Rounds\", \"Last Funding Date\", \n",
    "                             \"Last Funding Amount\", \"Total Funding Amount\", \"Status\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Founded Date</th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Funding Rounds</th>\n",
       "      <th>Last Funding Date</th>\n",
       "      <th>Last Funding Amount</th>\n",
       "      <th>Total Funding Amount</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#waywire</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>$1,750,000</td>\n",
       "      <td>$1,750,000</td>\n",
       "      <td>Was Acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*gram Labs</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>$1,000,000</td>\n",
       "      <td>$1,000,000</td>\n",
       "      <td>Operating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.io</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>$1,500,000</td>\n",
       "      <td>$1,500,000</td>\n",
       "      <td>Operating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/dev/color</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>Operating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 By 10</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>$120,000</td>\n",
       "      <td>Operating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Founded Date Closed Date  Funding Rounds Last Funding Date  \\\n",
       "0    #waywire   2012-06-01         NaT               1        2012-06-30   \n",
       "1  *gram Labs   2015-08-01         NaT               1        2016-07-27   \n",
       "2         .io   2015-03-01         NaT               1        2015-10-01   \n",
       "3  /dev/color   2015-05-01         NaT               1        2016-08-23   \n",
       "4    10 By 10   2015-01-01         NaT               1        2017-07-01   \n",
       "\n",
       "  Last Funding Amount Total Funding Amount        Status  \n",
       "0         $1,750,000           $1,750,000   Was Acquired  \n",
       "1         $1,000,000           $1,000,000      Operating  \n",
       "2         $1,500,000           $1,500,000      Operating  \n",
       "3           $120,000             $120,000      Operating  \n",
       "4           $120,000             $120,000      Operating  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_pf = companies_df.rename(columns={\n",
    "    \"Company Name\" : \"Company\",\n",
    "    \"Number of Funding Rounds\" : \"Funding Rounds\"   \n",
    "})\n",
    "companies_pf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read file and then sort \n",
    "funding = \"a_funding_rounds.csv\"\n",
    "funding_df = pd.read_csv(funding, encoding=\"iso-8859-1\", \n",
    "                         parse_dates=[\"Announced On Date\"])\n",
    "#funding_df.columns\n",
    "print(len(funding_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funding_df = funding_df[[\"Company Name\", \n",
    "                         \"Funding Type\", \n",
    "                         \"Money Raised\", \n",
    "                         \"Announced On Date\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_pf = funding_df.rename(columns={\n",
    "    \"Company Name\" : \"Company\"\n",
    "})\n",
    "funding_pf.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge companies_pf and funding_pf on Company\n",
    "# companies_pf = 8,664  funding_pf =  10,901  merged_data = 9,069\n",
    "merged_data = pd.merge(companies_pf, funding_pf,how=\"inner\",on=\"Company\")\n",
    "#merged_data.head(5)\n",
    "print(len(merged_data.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Data to csv without index, with header\n",
    "#merged_data.to_csv(\"company-funding.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read file and then sort - was organization.csv\n",
    "org = \"a_unique_organizations.csv\"\n",
    "unique_org = pd.read_csv(org, encoding=\"iso-8859-1\")\n",
    "#neworg.head(5)  \n",
    "print(len(unique_org.index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data = 9,069  org_df = 10,278  merged_df = 22,804  Why?\n",
    "merged_df = pd.merge(merged_data, unique_org, left_on=\"Company\", \n",
    "                     right_on=\"Company\", how='inner')\n",
    "merged_df.head(5)\n",
    "print(len(merged_df.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Data to csv without index, with header\n",
    "#merged_df.to_csv(\"merged_data-unique_org.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fields to usable formats\n",
    "merged_df[\"Money Raised\"] = merged_df[\"Money Raised\"].str.strip() \\\n",
    "                                                   .replace('[\\$,]','', regex=True ).astype(np.int64)\n",
    "    \n",
    "merged_df[\"Last Funding Amount\"] = merged_df[\"Last Funding Amount\"] \\\n",
    "                                                   .replace('[\\$,]','', regex=True ).astype(np.int64)\n",
    "merged_df[\"Total Funding Amount\"] = merged_df[\"Total Funding Amount\"] \\\n",
    "                                                   .replace('[\\$,]','', regex=True ).astype(np.int64)\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Data to csv without index, with header\n",
    "#merged_df.to_csv(\"all_files_merged_df.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expore the data\n",
    "min_found_date = min(merged_df[\"Founded Date\"])\n",
    "print(\"Min founded date \", min_found_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expore the data\n",
    "max_close_date = max(merged_df[\"Closed Date\"])\n",
    "print(\"Max closed date \", max_close_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expore the data\n",
    "# 286 records with Status == \"Closed\"\n",
    "closed_df = merged_df.loc[merged_df[\"Status\"] == \"Closed\"]\n",
    "closed_df.head(5)\n",
    "#print(len(closed_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9302 records with Status == \"Operating\"\n",
    "oper_df = merged_df.loc[merged_df[\"Status\"] == \"Operating\"]\n",
    "oper_df.head(5)\n",
    "#print(len(oper_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funding Type counts\n",
    "funding_type = merged_df[\"Funding Type\"].value_counts()\n",
    "funding_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby Funding Type and count states within each type\n",
    "status = merged_df.groupby('Funding Type')[\"Status\"].value_counts()\n",
    "status.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(status).rename(columns={\n",
    "    'Status':'Count'})\n",
    "\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_d = merged_df[merged_df['Funding Type'] == \"Series D\"]\n",
    "#series_d\n",
    "print(len(series_d.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_df = merged_df[merged_df['Funding Type'] == \"Seed\"]\n",
    "funding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = merged_df[merged_df['Status'] == \"Was Acquired\"].count\n",
    "seed_df = merged_df[merged_df['Funding Type'] == \"Seed\"]\n",
    "\n",
    "seed_df = seed_df[seed_df['Status'] == \"Was Acquired\"]\n",
    "\n",
    "seed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Build a scatter plot for each data type\n",
    "# plt.scatter(seed_df[\"Funding Type\"], \n",
    "#             seed_df[\"Status\"],\n",
    "#             s=100, edgecolor=\"black\", linewidths=1, c=\"red\", marker=\"o\", \n",
    "#             alpha=0.8)\n",
    "\n",
    "# # Incorporate the other graph properties\n",
    "# plt.title(\"Funding Type Status\")\n",
    "# plt.ylabel(\"Funding Type\")\n",
    "# plt.xlabel(\"Status\")\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Save the figure\n",
    "# plt.savefig(\"funding_type_scatter_chart.png\")\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #seed = merged_df[merged_df['Status'] == \"Operating\"]\n",
    "# seed = merged_df[merged_df['Status'] == \"Was Acquired\"]\n",
    "# seed = merged_df[merged_df['Status'] == \"Closed\"]\n",
    "# seed = merged_df[merged_df['Status'] == \"IPO\"]\n",
    "\n",
    "# # # x-axis\n",
    "# seed_operating = seed.groupby([\"Status\"]).count()[\"Closed\"]\n",
    "# # #y-axis\n",
    "# seed_acquired = seed.groupby([\"Status\"]).count()[\"Was Acquired\"]\n",
    "\n",
    "# # # x-axis\n",
    "# seed_closedt = seed.groupby([\"Status\"]).count()[\"Closed\"]\n",
    "# # #y-axis\n",
    "# seed_ips = seed.groupby([\"Status\"]).count()[\"IPO\"]\n",
    "\n",
    "# # # # x-axis\n",
    "# # rural_ride_count = rural_cities.groupby([\"city\"]).count()[\"fare\"]\n",
    "# # # #y-axis\n",
    "# # rural_driver_count = rural_cities.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "\n",
    "# # # # x-axis\n",
    "# # suburban_ride_count = suburban_cities.groupby([\"city\"]).count()[\"fare\"]\n",
    "# # # #y-axis\n",
    "# # suburban_driver_count = suburban_cities.groupby([\"city\"]).mean()[\"driver_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_sum = merged_df.groupby('Funding Type')[\"Money Raised\"].sum()\n",
    "funding_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12.0\n",
    "fig = plt.figure(figsize=[8, 8])\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "types_area = [\"Seed\", \"Series A\", \"Series B\", \"Series C\",\"Series D\" ]\n",
    "numbers = funding_sum\n",
    "colors = [\"gold\", \"lightcoral\", \"cyan\", \"lightgreen\", \"lightskyblue\"]\n",
    "explode = (0, 0.06, 0, 0, 0)\n",
    "\n",
    "x_axis = np.arange(0, len(types_area))\n",
    "\n",
    "ax.set_title(\"Funding Type Total Funding Percentages for Startups\", \n",
    "             weight='bold').set_fontsize('18')\n",
    "ax.pie(numbers, explode=explode, labels=types_area, colors=colors,\n",
    "       autopct=\"%1.2f%%\", textprops={'weight': 'bold', 'fontsize':'14'},\n",
    "       shadow=True, startangle=30)\n",
    "ax.axis(\"equal\")\n",
    "\n",
    "# Save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"funding_type_sum_pie_chart.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of counts is 10278\n",
    "funding_pct = merged_df.groupby('Funding Type')[\"Money Raised\"].count()\n",
    "funding_pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12.0\n",
    "\n",
    "fig = plt.figure(figsize=[8, 8])\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "types_area = [\"Seed\", \"Series A\", \"Series B\", \"Series C\",\"Series D\" ]\n",
    "numbers = funding_pct\n",
    "colors = [\"gold\", \"lightcoral\", \"cyan\", \"lightgreen\", \"lightskyblue\"]\n",
    "explode = (0.06, 0, 0, 0, 0)\n",
    "\n",
    "x_axis = np.arange(0, len(types_area))\n",
    "\n",
    "ax.set_title(\"Funding Type Percentages for Startups\", weight='bold').set_fontsize('18')\n",
    "\n",
    "ax.pie(numbers, explode=explode, \n",
    "       labels=types_area, colors=colors,\n",
    "       autopct=\"%1.2f%%\", textprops={'weight': 'bold', 'fontsize':'14'}, \n",
    "       shadow=True, startangle=30, pctdistance=.85, labeldistance=1.1)\n",
    "\n",
    "ax.axis(\"equal\")\n",
    "\n",
    "# Save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"funding_type_count_pie_chart.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y axis for funding_average_per_type_bar_chart \n",
    "fund_avgs = np.array(merged_df.groupby('Funding Type')[\"Money Raised\"].median())\n",
    "#fund_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x axis for funding_average_per_type_bar_chart \n",
    "funding_types = merged_df[\"Funding Type\"].unique()\n",
    "#funding_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funding_average_per_type_bar_chart \n",
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x_axis = np.arange(1, len(funding_types)+ 1)\n",
    "xtick_locations = [x for x in x_axis]\n",
    "\n",
    "ax.set_title(\"Funding Type Average Investment\", weight='bold').set_fontsize('18')\n",
    "ax.set_xlabel(\"Funding Types\", weight='bold').set_fontsize('14')\n",
    "ax.set_ylabel(\"Average Investments(10MM)\", weight='bold').set_fontsize('14')\n",
    "\n",
    "ax.set_xlim(0, len(funding_types)+ 1)\n",
    "\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "ax.bar(x_axis, fund_avgs, facecolor=\"red\", width=.4)\n",
    "ax.set_xticks(xtick_locations)\n",
    "\n",
    "ax.set_xticklabels(funding_types, rotation=35, weight='bold')\n",
    "ax.set_yticklabels([0,10,20,30,40,50,60,70],\n",
    "                   rotation=360, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"funding_type_avg_investment_bar_chart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File without urls required for screen scraping.  \n",
    "## Read file and then sort \n",
    "csv_file = \"top_50_orgs.csv\"\n",
    "top_50_orgs = pd.read_csv(csv_file, encoding=\"iso-8859-1\", parse_dates=[\"Announced On Date\"])\n",
    "top_50_orgs = top_50_orgs.sort_values(\"Funding Type\").reset_index(drop=True)\n",
    "top_50_orgs[\"Homepage\"] = top_50_orgs[\"Homepage\"].replace(np.nan, '', regex=True)\n",
    "top_50_orgs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The original top_orgs.xslx had the wrong url so this is a \n",
    "# # manual process to get the Homepage for Screen Scraping.\n",
    "# # To sutomate the url retrievel process you can build off \n",
    "# # this manual process.\n",
    "# # \n",
    "# # 1) Remove duplicates from copy of merged_df\n",
    "# # 2) Copy the output into top_orgs_search_results.txt\n",
    "# # 3) Manually copy the homepage url into top_orgs.xlsx and\n",
    "# #    create top_orgs.csv.\n",
    "# # 4) Searched organizations.xlsx manually and found Ripcord, \n",
    "# #    IndoorAtlas, and Truss.\n",
    "# # 5) Found 46 of 50 urls.\n",
    "\n",
    "# Copy merged_df to a temp data frame for processing\n",
    "tmp_merged_df = merged_df\n",
    "\n",
    "# Remove duplicates method 1:\n",
    "# tmp_merged_df = tmp_merged_df.groupby([\"Company\",\"Homepage\"]).max()\n",
    "# tmp_merged_df.reset_index(inplace=True)\n",
    "# or\n",
    "# Remove duplicates method 2:\n",
    "tmp_merged_df = tmp_merged_df.drop_duplicates(subset=[\"Company\",\"Homepage\"],\n",
    "                                              keep=\"last\").reset_index(drop=True)\n",
    "# print(len(tmp_merged_df.index))\n",
    "count = 0\n",
    "\n",
    "## Iterate over the top_orgs rows and lookup the homepage via the Company\n",
    "## This doesn't give what I want so I manually copied the url into top_orgs.xlsx\n",
    "## and created top_orgs.csv.\n",
    "for index, row in top_50_orgs.iterrows():\n",
    "    try:\n",
    "        # Use Company to get Homepage\n",
    "        print(\"This is the result for: \", row[\"Company\"])\n",
    "        #print(tmp_merged_df.loc[tmp_merged_df[\"Company\"] == row[\"Company\"],[\"Homepage\"]].values)\n",
    "        print(tmp_merged_df.loc[tmp_merged_df[\"Company\"] == row[\"Company\"],[\"Homepage\"]])\n",
    "        count += 1\n",
    "        ## Set the cell info for Homepage (Doesn't work!)\n",
    "        # example: print(df.loc[df['D'] == 14]['A'].values)\n",
    "        #url = tmp_merged_df.loc[tmp_merged_df[\"Company\"] == row[\"Company\"],[\"Homepage\"]]\n",
    "        #top_50_orgs.set_value(index, \"Homepage\", url)\n",
    "    except:\n",
    "        print(\"Error for: \", row[\"Company\"])  \n",
    "\n",
    "print(\"top_orgs rows processed: \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File with url manually added for screen scraping using\n",
    "## the output file top_orgs_match_orgs_results.docx\n",
    "## Read file and then sort \n",
    "csv_file = \"top_orgs.csv\"\n",
    "top_orgs = pd.read_csv(csv_file, encoding=\"iso-8859-1\", parse_dates=[\"Announced On Date\"])\n",
    "top_orgs = top_orgs.sort_values(\"Funding Type\").reset_index(drop=True)\n",
    "top_orgs.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "top_orgs[\"Money Raised\"] = top_orgs[\"Money Raised\"].replace('[\\$,]','', regex=True).astype(np.int64)\n",
    "top_orgs[\"Homepage\"] = top_orgs[\"Homepage\"].replace(np.nan, '', regex=True)\n",
    "\n",
    "top_orgs[\"Total Visits\"] = \"\"\n",
    "top_orgs[\"Avg Visit Duration\"] = \"\"\n",
    "top_orgs[\"Pages Per Visit\"] = \"\"\n",
    "top_orgs[\"Bounce Rate\"] = \"\"\n",
    "print(len(top_orgs.index))\n",
    "top_orgs.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save file with urls prior to scraping.to csv without index, with header\n",
    "#top_orgs.to_csv(\"pre-screen_scrape_data.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Web scraping program with 20 second sleep time.\n",
    "## Consider using a smaller subset of data for scraping.\n",
    "\n",
    "##  Test URL https://www.similarweb.com/website/shotput.com#overview \n",
    "\n",
    "## Splinter documenation:\n",
    "## https://github.com/douglasmiranda/splinter-examples/blob/master/another_examples/screenshot.py\n",
    "## http://splinter.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "## BeautifulSoup Documentation:\n",
    "## https://www.crummy.com/software/BeautifulSoup/bs4/doc\n",
    "\n",
    "\n",
    "# from splinter import Browser\n",
    "# import csv\n",
    "# from bs4 import BeautifulSoup \n",
    "# import time\n",
    "\n",
    "# # browser = Browser('chrome')\n",
    "# # browser = Browser('firefox')\n",
    "\n",
    "# with Browser() as browser:\n",
    "#     # Visit URL\n",
    "#     url1 = \"https://www.similarweb.com/website/\" \n",
    "#     url_suffix = \"#overview\"\n",
    "    \n",
    "#     # loop thru the urls top_orgs data frame \n",
    "#     counter = 0\n",
    "#     for index, row in top_orgs.iterrows():\n",
    "#         url = \"\"\n",
    "#         #print(type(row[\"Homepage\"]))\n",
    "#         url2 = row[\"Homepage\"].split('/')\n",
    "#         if len(url2) > 2:\n",
    "#             counter += 1\n",
    "#             url = url1 + url2[2] + url_suffix\n",
    "#             print(\"url counter: \", counter,end=\" - \")\n",
    "#             print(url)\n",
    "        \n",
    "#             try:\n",
    "#                 browser.visit(url)\n",
    "#                 time.sleep(20)\n",
    "#                 html = browser.html\n",
    "#                 soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "#                 #print(soup.prettify())\n",
    "   \n",
    "#                 count = 0\n",
    "#                 # Grab the 4 activity stats from the html \n",
    "#                 for line in soup.findAll('span',class_=\"engagementInfo-valueNumber js-countValue\"):\n",
    "#                     print(line.get_text())\n",
    "#                     count += 1\n",
    "#                     # Write to a data frame\n",
    "#                     if count == 1:\n",
    "#                         top_orgs.set_value(index, \"Total Visits\", line.getText())\n",
    "#                     elif count == 2:\n",
    "#                         top_orgs.set_value(index, \"Avg Visit Duration\", line.getText())\n",
    "#                     elif count == 3:\n",
    "#                         top_orgs.set_value(index, \"Pages Per Visit\", line.getText())\n",
    "#                     else:\n",
    "#                         top_orgs.set_value(index, \"Bounce Rate\", line.getText())\n",
    "#             except:\n",
    "#                 print(\"Error with url: \", url)  \n",
    "# top_orgs\n",
    "# print(\"urls processed: \", counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we screen scraped then save data to csv without index, with header\n",
    "#top_orgs.to_csv(\"post_screen_scrape_data.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload data to work with Screen scrape data without more scraping\n",
    "## Read file \n",
    "\n",
    "csv_file = \"post_screen_scrape_data.csv\"\n",
    "top_orgs = pd.read_csv(csv_file, encoding=\"iso-8859-1\", parse_dates=[\"Announced On Date\"])\n",
    "\n",
    "top_orgs[\"Money Raised\"] = top_orgs[\"Money Raised\"].replace('[\\$,]','', regex=True ).astype(np.int64)\n",
    "top_orgs[\"Homepage\"] = top_orgs[\"Homepage\"].replace(np.nan, '', regex=True)\n",
    "top_orgs[\"Total Visits\"] = top_orgs[\"Total Visits\"].replace(np.nan, 0, regex=True)\n",
    "top_orgs[\"Pages Per Visit\"] = top_orgs[\"Pages Per Visit\"].replace(np.nan, 0, regex=True)\n",
    "top_orgs[\"Bounce Rate\"] = top_orgs[\"Bounce Rate\"].replace(np.nan, 0, regex=True)\n",
    "\n",
    "top_orgs.head(7)\n",
    "#top_orgs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Remove rows we don't need to process\n",
    "# top_orgs = top_orgs.loc[top_orgs[\"Total Visits\"]!= \"\",[\"Company\",\"Funding Type\",\n",
    "#                            \"Money Raised\",\"Announced On Date\",\"Homepage\",\"Total Visits\",\n",
    "#                            \"Avg Visit Duration\",\"Pages Per Visit\",\"Bounce Rate\"]]\n",
    "\n",
    "#top_orgs.dtypes\n",
    "#print(len(top_orgs.index))\n",
    "#top_orgs.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex module\n",
    "import re  \n",
    "\n",
    "## Total Visits: strip non-numeric characters and convert to float64\n",
    "for index, row in top_orgs.iterrows():\n",
    "    print(\"index is: \", index)\n",
    "    print(row[\"Total Visits\"])\n",
    "    print(type(row[\"Total Visits\"]))\n",
    "    \n",
    "    str1 = str(row[\"Total Visits\"])\n",
    "    if \"K\" in str1:\n",
    "        str1 = re.sub('[<K]', '', str1)\n",
    "        flt_str1 = float(str1) * 1000\n",
    "        print(\"str1 with a K is \", str1)\n",
    "        top_orgs.set_value(index, \"Total Visits\", flt_str1)\n",
    "    else:\n",
    "        str1 = re.sub('[<M]', '', str1)\n",
    "        flt_str1 = float(str1) * 1000000\n",
    "        print(\"other str1 is \", str1)\n",
    "        top_orgs.set_value(index, \"Total Visits\", flt_str1)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "top_orgs[\"Total Visits\"] = top_orgs[\"Total Visits\"]      \n",
    "top_orgs   \n",
    "#top_orgs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert string columns into usable data types\n",
    "\n",
    "## Convert a column to datetime64 type with only the time?\n",
    "## pd.to_datetime.dt.time is a datetime.time object but not datetime64.\n",
    "## Therefore, it is correct that the dtype for the column is object.  \n",
    "## Converting Avg Visit Duration to datetime.time renders the desired \n",
    "## format 00:00:00.\n",
    "## Check out this documentation on Time series:\n",
    "## https://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "\n",
    "top_orgs[\"Avg Visit Duration\"] = pd.to_datetime(top_orgs[\"Avg Visit Duration\"],format=\"%H:%M:%S\").dt.time\n",
    "\n",
    "top_orgs[\"Bounce Rate\"] = top_orgs[\"Bounce Rate\"].replace('[%]','', regex=True ).astype(np.float64)\n",
    "\n",
    "top_orgs[\"Pages Per Visit\"] = top_orgs[\"Pages Per Visit\"].astype(np.float64)\n",
    "\n",
    "top_orgs\n",
    "#top_orgs.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
